{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Some Libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadModel:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            model_data = json.load(f)\n",
    "        \n",
    "        layers = model_data['layers']\n",
    "        n_layers = len(layers)\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.activations = []\n",
    "        self.input = []\n",
    "        self.target = []\n",
    "        self.sigmoid_gradient = lambda x: x * (1. - x)\n",
    "        self.relu_gradient = lambda x: 1. * (x > 0)\n",
    "        self.linear_gradient = lambda x: np.ones_like(x)\n",
    "        self.tanh_gradient = lambda x: 1 - np.tanh(x)**2\n",
    "        self.softmax_gradient = lambda x: x * (1. - x)\n",
    "        self.learning_rate = model_data['learning_parameters']['learning_rate']\n",
    "        self.batch_size = model_data['learning_parameters']['batch_size']\n",
    "        self.epochs = model_data['learning_parameters']['max_iteration']\n",
    "        self.error = model_data['learning_parameters']['error_threshold']\n",
    "        \n",
    "        \n",
    "        for i in range(1, n_layers):\n",
    "            layer = layers[i]\n",
    "            \n",
    "            if layer['tipe'] == 'hidden':\n",
    "                n_neurons = layer['n_neuron']\n",
    "                weight = np.array(layer['weight']).astype(np.float64)\n",
    "                bias = np.array(layer['bias']).astype(np.float64)\n",
    "                activation = layer['activation_function']\n",
    "                input_layer = layer['input']\n",
    "                target = layer['target']\n",
    "                \n",
    "                self.weights.append(weight)\n",
    "                self.biases.append(bias)\n",
    "                self.activations.append(activation)\n",
    "                self.input.append(input_layer)\n",
    "                self.target.append(target)\n",
    "                \n",
    "            elif layer['tipe'] == 'output':\n",
    "                n_neurons = layer['n_neuron']\n",
    "                weight = np.array(layer['weight']).astype(np.float64)\n",
    "                bias = np.array(layer['bias']).astype(np.float64)\n",
    "                activation = layer['activation']\n",
    "                input_layer = layer['input']\n",
    "                target = layer['target']\n",
    "                \n",
    "                self.weights.append(weight)\n",
    "                self.biases.append(bias)\n",
    "                self.activations.append(activation)\n",
    "                self.input.append(input_layer)\n",
    "                self.target.append(target)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def get_biases(self):\n",
    "        return self.biases\n",
    "    \n",
    "    def get_input(self):\n",
    "        return self.input\n",
    "    \n",
    "    def get_target(self):\n",
    "        return self.target\n",
    "    \n",
    "    def get_activations(self):\n",
    "        return self.activations\n",
    "    \n",
    "    def get_learning_rate(self):\n",
    "        return self.learning_rate\n",
    "    \n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "    \n",
    "    def get_epochs(self):\n",
    "        return self.epochs\n",
    "    \n",
    "    def get_layer(self, layer):\n",
    "        return self.weights[layer], self.biases[layer], self.activations[layer]\n",
    "    \n",
    "    def get_layer_weights(self, layer):\n",
    "        return self.weights[layer]\n",
    "    \n",
    "    def get_layer_biases(self, layer):\n",
    "        return self.biases[layer]\n",
    "    \n",
    "    def get_layer_activations(self, layer):\n",
    "        return self.activations[layer]\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.weights, self.biases, self.activations\n",
    "    \n",
    "    def get_activation_gradient(self, activation):\n",
    "        if activation == 'relu':\n",
    "            return lambda x: 1. * (x > 0)\n",
    "        elif activation == 'sigmoid':\n",
    "            return lambda x: x * (1. - x)\n",
    "        elif activation == 'linear':\n",
    "            return lambda x: np.ones_like(x)\n",
    "        elif activation == 'softmax':\n",
    "            return lambda x: x * (1. - x)\n",
    "\n",
    "    \n",
    "    # print model per layer\n",
    "    def print_model(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            print('Layer', i+1)\n",
    "            print(self.biases[i])\n",
    "            print(self.weights[i])\n",
    "            print(self.activations[i])\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "[0.1 0.2]\n",
      "[[ 0.3861139  -0.48568122]\n",
      " [ 0.7138861   0.78568122]]\n",
      "softmax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class FFNN:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = LoadModel(model_path)\n",
    "        self.weights = self.model.get_weights()\n",
    "        self.biases = self.model.get_biases()\n",
    "        self.activations = self.model.get_activations()\n",
    "        self.input = self.model.get_input()\n",
    "        self.target = self.model.get_target()\n",
    "        self.learning_rate = self.model.get_learning_rate()\n",
    "        self.batch_size = self.model.get_batch_size()\n",
    "        self.epochs = self.model.get_epochs()\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        input_layer = X\n",
    "        self.layer_outputs = []  # save outputs of each layer\n",
    "        n_layers = len(self.weights) + 1\n",
    "        for i in range(n_layers - 1):\n",
    "            dot_product = np.dot(input_layer, self.weights[i]) + self.biases[i]\n",
    "            if self.activations[i] == 'relu':\n",
    "                output_layer = np.maximum(0, dot_product)\n",
    "            elif self.activations[i] == 'sigmoid':\n",
    "                output_layer = 1 / (1 + np.exp(-dot_product))\n",
    "            elif self.activations[i] == 'linear':\n",
    "                output_layer = dot_product\n",
    "            elif self.activations[i] == 'softmax':\n",
    "                output_layer = np.exp(dot_product) / np.sum(np.exp(dot_product), axis=0)\n",
    "            input_layer = output_layer\n",
    "            self.layer_outputs.append(input_layer)\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "    def backward_propagation(self, X, y_true, learning_rate):\n",
    "        n_samples = len(X)\n",
    "        n_layers = len(self.weights) + 1\n",
    "\n",
    "        # calculate gradient for the last layer\n",
    "        y_pred = self.layer_outputs[-1]\n",
    "        if self.activations[-1] == 'sigmoid': \n",
    "            error = (y_pred - y_true) * self.model.sigmoid_gradient(y_pred)\n",
    "        elif self.activations[-1] == 'relu':\n",
    "            error = (y_pred - y_true) * self.model.relu_gradient(y_pred)\n",
    "        elif self.activations[-1] == 'linear':\n",
    "            error = (y_pred - y_true) * self.model.linear_gradient(y_pred)\n",
    "        elif self.activations[-1] == 'softmax':\n",
    "            error = (y_pred - y_true) * self.model.softmax_gradient(y_pred)\n",
    "\n",
    "        # calculate gradient for the other layers\n",
    "        for i in range(n_layers - 2, -1, -1):\n",
    "            X_with_bias = np.concatenate((X, np.tile([1], (X.shape[0], 1)).reshape(X.shape[0], 1)), axis=1)\n",
    "            gradient = np.dot(error.T, X_with_bias)\n",
    "            weight_gradient = gradient[:, :-1]\n",
    "            bias_gradient = gradient[:, -1:]\n",
    "\n",
    "            self.weights[i] -= learning_rate * weight_gradient.T\n",
    "            self.biases[i] -= learning_rate * (bias_gradient.T)[0]\n",
    "\n",
    "            new_m = np.append(self.weights[i], [self.biases[i]], axis=0)\n",
    "            \n",
    "            if self.activations[i] == 'sigmoid':\n",
    "                new_m = np.ones_like(self.layer_outputs[i])\n",
    "                error = np.dot(error, new_m.T) * self.model.sigmoid_gradient(self.layer_outputs[i])\n",
    "            elif self.activations[i] == 'relu':\n",
    "                error = np.dot(error, new_m.T) * self.model.relu_gradient(self.layer_outputs[i])\n",
    "            elif self.activations[i] == 'linear':\n",
    "                error = np.dot(error, new_m.T) * self.model.linear_gradient(self.layer_outputs[i])\n",
    "            elif self.activations[i] == 'softmax':\n",
    "                error = np.dot(error, self.weights[i].T) * self.model.softmax_gradient(self.layer_outputs[i])\n",
    "\n",
    "    def train(self, X, y_true, learning_rate, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            # shuffle the training data\n",
    "            p = np.random.permutation(len(X))\n",
    "            X, y_true = X[p], y_true[p]\n",
    "            \n",
    "\n",
    "            # split the data into mini-batches\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch, y_batch = X[i:i+batch_size], y_true[i:i+batch_size]\n",
    "\n",
    "                # forward propagation\n",
    "                self.forward_propagation(X_batch)\n",
    "\n",
    "                # backward propagation\n",
    "                self.backward_propagation(X_batch, y_batch, learning_rate)\n",
    "\n",
    "            y_pred = self.predict(X)\n",
    "            loss = np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "            if loss < 0.01:\n",
    "                break\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            return self.forward_propagation(X)\n",
    "        else:\n",
    "            predictions = []\n",
    "            for instance in X:\n",
    "                predictions.append(self.forward_propagation(instance))\n",
    "            return np.array(predictions)\n",
    "\n",
    "    def accuracy(self, X, y_true):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred = (y_pred >= 0.5).astype(int)\n",
    "        return np.mean(y_pred == y_true)\n",
    "\n",
    "    def print_model(self):\n",
    "        self.model.print_model()\n",
    "\n",
    "    def draw_network(self):\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        pos = {}\n",
    "\n",
    "        # add nodes\n",
    "        input_nodes = [f'X_{i + 1}' for i in range(len(self.weights[0]))]\n",
    "        G.add_nodes_from(input_nodes, layer='Input')\n",
    "        G.add_nodes_from(['b0'], layer='Bias')\n",
    "        for i in range(len(input_nodes)):   \n",
    "            pos[f'X_{i + 1}'] = [0, i + 1]\n",
    "        pos['b0'] = [0, len(self.weights[0]) + 1]\n",
    "\n",
    "        hidden_nodes = []\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            hidden_nodes.append([f'h{i + 1}_{j + 1}' for j in range(len(self.weights[i][0]))])\n",
    "            G.add_nodes_from(hidden_nodes[i], layer='Hidden')\n",
    "            G.add_nodes_from([f'b{i + 1}'], layer='Bias')\n",
    "            for j in range(len(hidden_nodes[i])):\n",
    "                pos[f'h{i + 1}_{j + 1}'] = [i + 1, j + 1]\n",
    "            pos[f'b{i + 1}'] = [i + 1, len(self.weights[i][0]) + 1]\n",
    "\n",
    "        output_nodes = [f'y_{i + 1}' for i in range(len(self.weights[-1][0]))]\n",
    "        G.add_nodes_from(output_nodes, layer='Output')\n",
    "        for i in range(len(output_nodes)):\n",
    "            pos[f'y_{i + 1}'] = [len(self.weights), i + 1]\n",
    "\n",
    "        # add edges\n",
    "        for i in range(len(self.weights)):\n",
    "            for j in range(len(self.weights[i])):\n",
    "                for k in range(len(self.weights[i][j])):\n",
    "                    if i == 0:\n",
    "                        G.add_edge(input_nodes[j], hidden_nodes[i][k], weight=self.weights[i][j][k])\n",
    "                        G.add_edge(f'b0', hidden_nodes[i][k], weight=self.biases[i][k])\n",
    "                    elif i == len(self.weights) - 1:\n",
    "                        G.add_edge(hidden_nodes[i - 1][j], output_nodes[k], weight=self.weights[i][j][k])\n",
    "                        G.add_edge(f'b{i}', output_nodes[k], weight=self.biases[i][k])\n",
    "                    else:\n",
    "                        G.add_edge(hidden_nodes[i - 1][j], hidden_nodes[i][k], weight=self.weights[i][j][k])\n",
    "                        G.add_edge(f'b{i}', hidden_nodes[i][k], weight=self.biases[i][k])\n",
    "\n",
    "        # draw network\n",
    "        edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=1500, node_color='lightblue')\n",
    "        nx.draw_networkx_edges(G, pos, width=2, edge_color='black', arrows=True, arrowsize=25)\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, label_pos=0.60)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# main function\n",
    "def main():\n",
    "    # load model\n",
    "    # filename = input(\"Enter the filename: \")\n",
    "    filename = 'softmax'\n",
    "    model_path = filename + '.json'\n",
    "    model = FFNN(model_path)\n",
    "    \n",
    "    # input linear\n",
    "    X_train = model.input[0]\n",
    "    Y_train = model.target[0]\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    # train model\n",
    "    model.train(X_train, Y_train, model.learning_rate, model.epochs, model.batch_size)\n",
    "\n",
    "    # print model\n",
    "    model.print_model()\n",
    "\n",
    "    # draw network\n",
    "    # model.draw_network()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
